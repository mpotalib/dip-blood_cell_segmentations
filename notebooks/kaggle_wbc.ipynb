{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WBC Segmentation (Unstained) - Kaggle GPU Notebook\n",
    "\n",
    "Run this end-to-end in a Kaggle Notebook with GPU. Adjust the dataset path as noted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repo if not already present (Kaggle starts in /kaggle/working)\n",
    "import os, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_URL = \"https://github.com/emctalib/dip-blood_cell_segmentations.git\"\n",
    "REPO_DIR = Path(\"/kaggle/working/dip-blood_cell_segmentations\")\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL, str(REPO_DIR)], check=True)\n",
    "os.chdir(REPO_DIR)\n",
    "print(\"CWD:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to your Kaggle dataset containing data/train|val|test with images + masks (or annotations)\n",
    "# Example: upload a dataset and set DATASET_BASE to /kaggle/input/your-dataset-name\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "\n",
    "DATASET_BASE = Path(\"/kaggle/input/your-dataset\")  # TODO: set to your dataset name\n",
    "TARGET = Path(\"data\")\n",
    "\n",
    "if not DATASET_BASE.exists():\n",
    "    raise FileNotFoundError(f\"Dataset path not found: {DATASET_BASE}. Update DATASET_BASE above.\")\n",
    "\n",
    "# If data is already structured as data/train/images etc, just symlink\n",
    "if TARGET.exists():\n",
    "    shutil.rmtree(TARGET)\n",
    "os.symlink(DATASET_BASE, TARGET)\n",
    "print(\"Linked\", DATASET_BASE, \"->\", TARGET)\n",
    "\n",
    "# If masks are not pre-generated but annotations exist, create masks\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_dir = TARGET / split / \"images\"\n",
    "    ann_dir = TARGET / split / \"annotations\"\n",
    "    mask_dir = TARGET / split / \"masks\"\n",
    "    if img_dir.exists() and ann_dir.exists() and not mask_dir.exists():\n",
    "        mask_dir.mkdir(parents=True, exist_ok=True)\n",
    "        !python prepare_masks.py --images-dir {img_dir} --annotations-dir {ann_dir} --output-dir {mask_dir}\n",
    "    else:\n",
    "        print(f\"Split {split}: images={img_dir.exists()}, annotations={ann_dir.exists()}, masks={mask_dir.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (baseline config uses AMP and will leverage GPU if available)\n",
    "!python train.py --config experiments/baseline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on val/test and export qualitative masks for the report/deck\n",
    "!python evaluate.py --config experiments/baseline.yaml --checkpoint outputs/baseline/checkpoints/best.pt --split val --save-dir outputs/preds_val --limit 20\n",
    "!python evaluate.py --config experiments/baseline.yaml --checkpoint outputs/baseline/checkpoints/best.pt --split test --save-dir outputs/preds_test --limit 20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
