{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WBC Segmentation (Unstained) - Kaggle GPU Notebook\n",
    "\n",
    "Run this end-to-end in a Kaggle Notebook with GPU. Adjust the dataset path as noted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repo if not already present (Kaggle starts in /kaggle/working)\n",
    "import os, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_URL = \"https://github.com/mpotalib/dip-blood_cell_segmentations.git\"\n",
    "REPO_DIR = Path(\"/kaggle/working/dip-blood_cell_segmentations\")\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL, str(REPO_DIR)], check=True)\n",
    "os.chdir(REPO_DIR)\n",
    "print(\"CWD:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857de723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to your Kaggle dataset containing data/train|val|test with images + masks (or annotations)\n",
    "# Example: upload a dataset and set DATASET_BASE to /kaggle/input/your-dataset-name\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "\n",
    "DATASET_BASE = Path(\"/kaggle/input/dip-wbc-dataset\")  # TODO: set to your dataset name\n",
    "TARGET = Path(\"data\")\n",
    "\n",
    "if not DATASET_BASE.exists():\n",
    "    raise FileNotFoundError(f\"Dataset path not found: {DATASET_BASE}. Update DATASET_BASE above.\")\n",
    "\n",
    "# If data is already structured as data/train/images etc, just symlink\n",
    "if TARGET.exists():\n",
    "    if TARGET.is_symlink():\n",
    "        TARGET.unlink()\n",
    "    else:\n",
    "        shutil.rmtree(TARGET)\n",
    "os.symlink(DATASET_BASE, TARGET)\n",
    "print(\"Linked\", DATASET_BASE, \"->\", TARGET)\n",
    "\n",
    "# If masks are not pre-generated but annotations exist, create masks\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_dir = TARGET / split / \"images\"\n",
    "    ann_dir = TARGET / split / \"annotations\"\n",
    "    mask_dir = TARGET / split / \"masks\"\n",
    "    if img_dir.exists() and ann_dir.exists() and not mask_dir.exists():\n",
    "        mask_dir.mkdir(parents=True, exist_ok=True)\n",
    "        !python prepare_masks.py --images-dir {img_dir} --annotations-dir {ann_dir} --output-dir {mask_dir}\n",
    "    else:\n",
    "        print(f\"Split {split}: images={img_dir.exists()}, annotations={ann_dir.exists()}, masks={mask_dir.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fce12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (choose config: baseline or deeplab)\n",
    "!python train.py --config experiments/deeplab.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be815e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on val/test and export qualitative masks for the report/deck\n",
    "!python evaluate.py --config experiments/deeplab.yaml --checkpoint outputs/deeplab/checkpoints/best.pt --split val --save-dir outputs/deeplab/preds_val --limit 20\n",
    "!python evaluate.py --config experiments/deeplab.yaml --checkpoint outputs/deeplab/checkpoints/best.pt --split test --save-dir outputs/deeplab/preds_test --limit 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ce68d",
   "metadata": {},
   "source": [
    "## Train with log and plot curves\n",
    "Use tee to capture stdout to train.log, then parse and plot train/val curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f73afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DeepLab and save log for plotting\n",
    "!python train.py --config experiments/deeplab.yaml | tee train.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse train.log and plot loss/Dice curves\n",
    "import re, matplotlib.pyplot as plt\n",
    "train_loss, val_loss, val_dice = [], [], []\n",
    "with open('train.log') as f:\n",
    "    for line in f:\n",
    "        m = re.search(r'Epoch (\\d+)/(\\d+).*train loss ([0-9.]+)', line)\n",
    "        if m:\n",
    "            train_loss.append(float(m.group(3)))\n",
    "        m = re.search(r'Validation - loss: ([0-9.]+) \\| dice: ([0-9.]+)', line)\n",
    "        if m:\n",
    "            val_loss.append(float(m.group(1)))\n",
    "            val_dice.append(float(m.group(2)))\n",
    "if train_loss and val_loss:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(train_loss, label='train loss')\n",
    "    plt.plot(val_loss, label='val loss')\n",
    "    plt.xlabel('epoch'); plt.ylabel('loss'); plt.legend(); plt.tight_layout()\n",
    "if val_dice:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(val_dice, label='val Dice')\n",
    "    plt.xlabel('epoch'); plt.ylabel('Dice'); plt.legend(); plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
